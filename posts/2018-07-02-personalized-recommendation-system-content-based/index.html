<!DOCTYPE html>
<html lang="en-us" class="wf-firasans-n4-active wf-active">
	<head>
    <link href="http://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <!-- Enable responsiveness on mobile devices --> 
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
    
    	
    <meta name="generator" content="Hugo 0.36.1" />
    
    <title>Personalized recommendation system for articles - Content-based &middot; DL</title>
    <meta content="Personalized recommendation system for articles - Content-based - DL" property="og:title">
    <meta content=" - " property="og:description">    
    <!-- CSS --> 
    <link rel="stylesheet" href="https://darwinleung.github.io/css/print.css" media="print">
    <link rel="stylesheet" href="https://darwinleung.github.io/css/poole.css">
    <link rel="stylesheet" href="https://darwinleung.github.io/css/hyde.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira+Sans:300,300i,400,400i,500">
    
    <script defer src="https://use.fontawesome.com/releases/v5.0.9/js/all.js" integrity="sha384-8iPTk2s/jMVj81dnzb/iFR2sdA7u06vHJyyLlAd4snFpCl/SnyUjRrbdJsw1pGIl" crossorigin="anonymous"></script>
    <!-- highlight.js--> 
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/dark.min.css">
    <!-- Customised CSS -->
    <link rel="stylesheet" href="https://darwinleung.github.io/css/custom.css">
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="/favicon.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    

	</head>
    <body class="theme-base-0g " >
        <div class="sidebar">
	<div class="container text-center sidebar-sticky">
		<div class="sidebar-about text-center">
			<a href="https://darwinleung.github.io/"><h1 class="brand">DL</h1></a>
			 <img src="/img/DL_symbol.jpg" alt="Author Image" class="img-circle headshot center"> 
			<p class="lead">
				 Darwin&#39;s personal blog 
			</p>
		</div>
		
<div>
	<ul class="sidebar-nav">
		
		
				<li>
					<a href="/posts/"> <span>Posts</span></a>
				</li>
				<li>
					<a href="/about/"> <span>About</span></a>
				</li>
				<li>
					<a href="/contact/"> <span>Contact</span></a>
				</li>
		</li>
	</ul>
</div>

        <p>
		<section class="row text-center">
	
	
	
	&nbsp;<a href="https://github.com/darwinleung"><i class="fab fa-github fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	&nbsp;<a href="https://linkedin.com/in/darwinleung"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	&nbsp;<a href="mailto:darwinlkh@gmail.com"><i class="fas fa-at fa-lg" aria-hidden="true"></i></a>
	
</section>

        </p>
		<p class="copyright">Built with Hugo and Hyde-hyde Â©2018.
        </p>
	</div>
	<div>
	</div>
</div>

        <div class="content container">
            <div class="post">
  <h1>Personalized recommendation system for articles - Content-based</h1>
  
  <div class="col-sm-12 col-md-12">
    <span class="text-left post-date meta">
            
       
        <i class="fas fa-calendar-alt"></i> Jul 2, 2018
      
      
        
        
            in
            
            
                <a class="meta" href="/categories/data-science">DATA SCIENCE</a>
                ,
            
                <a class="meta" href="/categories/feature-extraction">FEATURE EXTRACTION</a>
                ,
            
                <a class="meta" href="/categories/machine-learning">MACHINE LEARNING</a>
                ,
            
                <a class="meta" href="/categories/recommedation-system">RECOMMEDATION SYSTEM</a>
                
            
        
      
      
      
        
        
            <br/>
             <i class="fas fa-tags"></i>
            
            <a class="meta" href="/tags/content-based">content-based</a> 
        
            <a class="meta" href="/tags/knn">knn</a> 
        
            <a class="meta" href="/tags/python">python</a> 
        
            <a class="meta" href="/tags/recommendation">recommendation</a> 
        
            <a class="meta" href="/tags/sklearn">sklearn</a>
        
      
      
      </span>  
  </div>    
  
  

<h1 id="personalized-recommendation-system-for-articles-content-based">Personalized recommendation system for articles - Content-based</h1>

<p>We use the same example from CF post, let&rsquo;s say we have the same 6 articles and 5 visitors and their view history data. Also, we have data about the context of each articles, like title, author, categories, length, no. of picture, and the words from the articles. We might also have data from the user side like their demographic, gender, ages, country etc. We can make use of all these data to build our recommendation. Compare with CF, we only need user behavioral data to make a recommendation.</p>

<p>There are 3 main steps in content-based:</p>

<ol>
<li>Item representation: Generate feature representing article (content itself, frequency of words, length, author, category etc.)</li>
<li>User representation: view or not/ session duration/ scroll depth etc.</li>
<li>Distance/ Similarity measure</li>
</ol>

<h2 id="find-similar-articles-using-content-based">Find similar articles using content-based</h2>

<p>First, let assume we already pre-process the content-related data for articles and reduce the feature space to 3 abstract dimensions about context and let&rsquo;s say we label them &ldquo;dog-ness&rdquo;, &ldquo;cat-ness&rdquo;, &ldquo;food-ness&rdquo;. Of course in reality we might not be able to label them as they are abstract dimensions. In this case, maybe we just count how many times the word &ldquo;dog&rdquo;/ &ldquo;cat&rdquo;/ &ldquo;food&rdquo; appear in the article and use that to define our features.</p>

<p>Dummy data:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">article_features <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([[<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">0.8</span>,<span style="color:#ae81ff">0</span>],[<span style="color:#ae81ff">0.99</span>,<span style="color:#ae81ff">0.2</span>,<span style="color:#ae81ff">0</span>],[<span style="color:#ae81ff">0.5</span>,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">0.1</span>],[<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">0.1</span>,<span style="color:#ae81ff">1</span>],[<span style="color:#ae81ff">0.1</span>,<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">0.99</span>],[<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">0.9</span>]])
df2 <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(article_features,columns <span style="color:#f92672">=</span> [<span style="color:#e6db74"></span><span style="color:#e6db74">&#39;dogness&#39;</span>,<span style="color:#e6db74"></span><span style="color:#e6db74">&#39;catness&#39;</span>,<span style="color:#e6db74"></span><span style="color:#e6db74">&#39;foodness&#39;</span>], index <span style="color:#f92672">=</span> [<span style="color:#e6db74"></span><span style="color:#e6db74">&#39;dog1&#39;</span>, <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;dog2&#39;</span>, <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;cat&#39;</span>, <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;food1&#39;</span>, <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;food2&#39;</span>,<span style="color:#e6db74"></span><span style="color:#e6db74">&#39;food3&#39;</span>])
df2<span style="color:#f92672">.</span>transpose()</code></pre></div>
<table>
<thead>
<tr>
<th></th>
<th>dog1</th>
<th>dog2</th>
<th>cat</th>
<th>food1</th>
<th>food2</th>
<th>food3</th>
</tr>
</thead>

<tbody>
<tr>
<td>dogness</td>
<td>1.0</td>
<td>0.99</td>
<td>0.5</td>
<td>0.0</td>
<td>0.10</td>
<td>0.0</td>
</tr>

<tr>
<td>catness</td>
<td>0.8</td>
<td>0.20</td>
<td>1.0</td>
<td>0.1</td>
<td>0.00</td>
<td>0.0</td>
</tr>

<tr>
<td>foodness</td>
<td>0.0</td>
<td>0.00</td>
<td>0.1</td>
<td>1.0</td>
<td>0.99</td>
<td>0.9</td>
</tr>
</tbody>
</table>

<p>In this example, dog1 article talks a lot about dog (1.0), and also cat (0.8) while dog2 article also talks about dog (0.99) a lot but just a bit about cats (0.2) and so on. Hence, we can represent an article by a vector like [1, 0.8, 0] and it represents what the article is about. We can apply KNN to find similar articles.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">model_knn <span style="color:#f92672">=</span> NearestNeighbors(metric <span style="color:#f92672">=</span> <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;cosine&#39;</span>, algorithm <span style="color:#f92672">=</span> <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;brute&#39;</span>)
model_knn<span style="color:#f92672">.</span>fit(df2<span style="color:#f92672">.</span>values)</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">i <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span>
distances, indices <span style="color:#f92672">=</span> model_knn<span style="color:#f92672">.</span>kneighbors(df2<span style="color:#f92672">.</span>values[i]<span style="color:#f92672">.</span>reshape(<span style="color:#ae81ff">1</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>),n_neighbors <span style="color:#f92672">=</span> <span style="color:#ae81ff">6</span>)

<span style="color:#66d9ef">for</span> j <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">0</span>, len(distances<span style="color:#f92672">.</span>flatten())):
    <span style="color:#66d9ef">if</span> j <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
        <span style="color:#66d9ef">print</span> <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;Recommendations for {0}:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>format(df2<span style="color:#f92672">.</span>index[i])
    <span style="color:#66d9ef">else</span>:
        <span style="color:#66d9ef">print</span> <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;{0}: {1}, with distance of {2}&#39;</span><span style="color:#f92672">.</span>format(j, df2<span style="color:#f92672">.</span>index[indices<span style="color:#f92672">.</span>flatten()[j]], distances<span style="color:#f92672">.</span>flatten()[j])</code></pre></div>
<pre><code>&gt; Recommendations for food2:

1: food3, with distance of 0.0050628109775:
2: food1, with distance of 0.0100004949996:
3: cat, with distance of 0.866598268802:
4: dog2, with distance of 0.901491367424:
5: dog1, with distance of 0.921523695125:
</code></pre>

<p>As expected, based on the category representation, we found the closest articles with food2 is food3, food1, cat, etc.</p>

<h2 id="personal-preference-prediction-with-matrix-factorization">Personal preference prediction with Matrix factorization</h2>

<p>Next, we can generate user representation based on their behavioral data, in this example, we simply use the same binary representation to indicate whether they view an article or not. For user_4:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">df<span style="color:#f92672">.</span>loc[[<span style="color:#e6db74"></span><span style="color:#e6db74">&#39;user_4&#39;</span>]]</code></pre></div>
<table>
<thead>
<tr>
<th></th>
<th>dog1</th>
<th>dog2</th>
<th>cat</th>
<th>food1</th>
<th>food2</th>
<th>food3</th>
</tr>
</thead>

<tbody>
<tr>
<td>user_4</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>

<p>Hence, we know this user viewed 2 food articles and 1 dog article. How can we combine this data with the item categorical representation above (i.e. dogness)? One simple method is to use the proportion of articles viewed, assuming user_4 see the title of all articles but only clicked into 3 of them. Hence we can get a vector for user preference like [<sup>1</sup>&frasl;<sub>2</sub> for dogness, 0 for catness, <sup>2</sup>&frasl;<sub>3</sub> for foodness ].</p>

<p>If we want to find out the likelihood given an article features vector, we can multiply them together, for example, we want to know the likelihood of user_4 on food1:
$$
\begin{bmatrix}
    0.5 &amp; 0 &amp; 0.66 <br />
    \end{bmatrix}
    \cdot
    \begin{bmatrix}
    0<br />
    0.1<br />
    1<br />
    \end{bmatrix} = 0.66
$$
user_4 on dog2:
$$
\begin{bmatrix}
    0.5 &amp; 0 &amp; 0.66 <br />
    \end{bmatrix}
    \cdot
    \begin{bmatrix}
    0.99<br />
    0.2<br />
    0<br />
    \end{bmatrix} = 0.495
$$
user_4 on cat:
$$
\begin{bmatrix}
    0.5 &amp; 0 &amp; 0.66 <br />
    \end{bmatrix}
    \cdot
    \begin{bmatrix}
    0.5<br />
    1<br />
    0.1<br />
    \end{bmatrix} = 0.316
$$
We can do this for any new articles then we can sort them by the likelihood, show them the highest N articles in the list. As Andrew Ng noted, we are basically fitting a linear regression to each item to predict their preference.</p>

<p>Of course, there are a lot of simplification and assumption made in this toy example. This is the basic idea of using content-based data for personalized recommendation.</p>

</div>
            <div class="footer">
                <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>

<script type="text/javascript">
    hljs.initHighlightingOnLoad();
</script>



            </div>
        </div>
        
        
<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-120240510-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='//www.google-analytics.com/analytics.js'></script>
        
    </body>
</html>
