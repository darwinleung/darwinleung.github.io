<!DOCTYPE html>
<html lang="en-us" class="wf-firasans-n4-active wf-active">
	<head>
    <link href="http://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <!-- Enable responsiveness on mobile devices --> 
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
    
    	
    <meta name="generator" content="Hugo 0.36.1" />
    
    <title>Extracting features from text - BoW, tfidf &middot; DL</title>
    <meta content="Extracting features from text - BoW, tfidf - DL" property="og:title">
    <meta content=" - " property="og:description">    
    <!-- CSS --> 
    <link rel="stylesheet" href="https://darwinleung.github.io/css/print.css" media="print">
    <link rel="stylesheet" href="https://darwinleung.github.io/css/poole.css">
    <link rel="stylesheet" href="https://darwinleung.github.io/css/hyde.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira+Sans:300,300i,400,400i,500">
    
    <script defer src="https://use.fontawesome.com/releases/v5.0.9/js/all.js" integrity="sha384-8iPTk2s/jMVj81dnzb/iFR2sdA7u06vHJyyLlAd4snFpCl/SnyUjRrbdJsw1pGIl" crossorigin="anonymous"></script>
    <!-- highlight.js--> 
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/dark.min.css">
    <!-- Customised CSS -->
    <link rel="stylesheet" href="https://darwinleung.github.io/css/custom.css">
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="/favicon.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    

	</head>
    <body class="theme-base-0g " >
        <div class="sidebar">
	<div class="container text-center sidebar-sticky">
		<div class="sidebar-about text-center">
			<a href="https://darwinleung.github.io/"><h1 class="brand">DL</h1></a>
			 <img src="/img/DL_symbol.jpg" alt="Author Image" class="img-circle headshot center"> 
			<p class="lead">
				 Darwin&#39;s personal blog 
			</p>
		</div>
		
<div>
	<ul class="sidebar-nav">
		
		
				<li>
					<a href="/posts/"> <span>Posts</span></a>
				</li>
				<li>
					<a href="/about/"> <span>About</span></a>
				</li>
				<li>
					<a href="/contact/"> <span>Contact</span></a>
				</li>
		</li>
	</ul>
</div>

        <p>
		<section class="row text-center">
	
	
	
	&nbsp;<a href="https://github.com/darwinleung"><i class="fab fa-github fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	&nbsp;<a href="https://linkedin.com/in/darwinleung"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	&nbsp;<a href="mailto:darwinlkh@gmail.com"><i class="fas fa-at fa-lg" aria-hidden="true"></i></a>
	
</section>

        </p>
		<p class="copyright">Built with Hugo and Hyde-hyde ©2018.
        </p>
	</div>
	<div>
	</div>
</div>

        <div class="content container">
            <div class="post">
  <h1>Extracting features from text - BoW, tfidf</h1>
  
  <div class="col-sm-12 col-md-12">
    <span class="text-left post-date meta">
            
       
        <i class="fas fa-calendar-alt"></i> May 9, 2018
      
      
        
        
            in
            
            
                <a class="meta" href="/categories/data-processing">DATA PROCESSING</a>
                ,
            
                <a class="meta" href="/categories/data-science">DATA SCIENCE</a>
                ,
            
                <a class="meta" href="/categories/feature-extraction">FEATURE EXTRACTION</a>
                ,
            
                <a class="meta" href="/categories/machine-learning">MACHINE LEARNING</a>
                
            
        
      
      
      
        
        
            <br/>
             <i class="fas fa-tags"></i>
            
            <a class="meta" href="/tags/bow">bow</a> 
        
            <a class="meta" href="/tags/python">python</a> 
        
            <a class="meta" href="/tags/sklearn">sklearn</a> 
        
            <a class="meta" href="/tags/text">text</a> 
        
            <a class="meta" href="/tags/tfidf">tfidf</a>
        
      
      
      </span>  
  </div>    
  
  

<p>Most of the machine learning algorithms work with numerical features only, they cannot work with raw text directly. Hence, we need to extract/generate numerical representation of textual data. One of the simplest way is to use the occurance or frequency of words.</p>

<h2 id="bag-of-words-bow">Bag-of-words (BoW)</h2>

<ul>
<li><p>Representation of text that describes the occurence of words within a document</p></li>

<li><p>Step:</p>

<ol>
<li>Find all unique words in a document, used as column (aka token)</li>
<li>Define the measure method (<sup>1</sup>&frasl;<sub>0</sub> for presence or absence of words, count, tfidf)</li>
<li>Calculate the measurement for each sentence, each row correspond to each sentence (aka tokenization)</li>
</ol></li>
</ul>

<p>Example:</p>

<p>Let&rsquo;s say we have 2 sentences in a document</p>

<ul>
<li>sentence 1: &ldquo;The earth is round, the pen is blue.&rdquo;</li>
<li>sentence 2: &ldquo;The earth is flat, my friend is you.&rdquo;</li>
</ul>

<p>Step1: generate &ldquo;tokens&rdquo; = [&ldquo;the&rdquo;, &ldquo;earth&rdquo;, &ldquo;is&rdquo;, &ldquo;round&rdquo;, &ldquo;pen&rdquo;, &ldquo;blue&rdquo;, &ldquo;my&rdquo;, &ldquo;friend&rdquo;, &ldquo;you&rdquo;]</p>

<p>Step2: word count</p>

<p>Step3: we count the occurance of each words in the tokens</p>

<ul>
<li>sentence 1: [2,1,2,1,1,1,0,0,0]</li>
<li>sentence 2: [1,1,2,0,0,0,1,1,1]</li>
</ul>

<p>Then we can use the resulting vectors as features in ML model.</p>

<h2 id="tf-idf">TF-IDF</h2>

<p>Similar with occurance and frequency, we can use the &ldquo;relative importance&rdquo; a word to a document and TF-IDF is the measure of the importance.</p>

<ul>
<li>Term-frequency-inverse document frequency</li>
<li>Increase proportionally to the number of times a word appears in the document</li>
<li>offset by the frequency of the word in the corpus</li>
<li>Can be used with BoW</li>
</ul>

<p>$$
tfidf(t,d,D) = tf(t,d) * idf(t,D)
$$</p>

<p>where tf()​ is the term frequency function and idf()​ is the inverse term frequency function, t is the text of interest, d is the document, D is the corpus containing multiple d. There are many variations on the definition of tf()​ and idf()​, one popular definition of tf()​ is relative term frequency and idf is the log of inverse ratio of documents that include the word t,</p>

<h2 id="example">Example</h2>

<p>​Let&rsquo;s say we have document d1 with 10 words, 2 of them are &ldquo;the&rdquo;, then tf(&ldquo;this&rdquo;, d1) = <sup>2</sup>&frasl;<sub>10</sub> = 0.2. Let&rsquo;s say we have 5 document in our corpus, and 4 of them consist of the &ldquo;the&rdquo; word, idf(&ldquo;this&rdquo;, D) = log(<sup>5</sup>&frasl;<sub>4</sub>) ~ 0.1. Hence, tfidf(&ldquo;this&rdquo;, d1, D) = 0.2 * 0.1 = 0.02. It means the word &ldquo;this&rdquo; is not very important in this document. If only 1 of the document consist of the &ldquo;the&rdquo; word, then idf(&ldquo;this&rdquo;, D) = log(5) = 0.7  and tfidf = 0.2 * 0.7 = 0.14 and so on.</p>

<p>Example modified from <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">wiki</a> . Very useful to understand.</p>

<h2 id="using-scikit-learn">Using scikit-learn</h2>

<p>Let&rsquo;s say we have a corpus</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">corpus <span style="color:#f92672">=</span> [
    <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;This is the first document.&#39;</span>,
    <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;This is the second second document.&#39;</span>,
    <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;And the third one.&#39;</span>,
    <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;Is this the first document?&#39;</span>,
]</code></pre></div>
<p>We can use scikit-learn&rsquo;s CountVectorizer to tokenize, X is a sparse matrix, use toarray() to see the actual values:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
count_vect <span style="color:#f92672">=</span> CountVectorizer()

X <span style="color:#f92672">=</span> count_vect<span style="color:#f92672">.</span>fit_transform(corpus)
X<span style="color:#f92672">.</span>toarray()</code></pre></div>
<p>Output is a row vector for each row showing the word count:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">array([[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>],
       [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>],
       [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>],
       [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>]], dtype<span style="color:#f92672">=</span>int64)</code></pre></div>
<p>To see the word correspond to each column:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">count_vect<span style="color:#f92672">.</span>get_feature_names()</code></pre></div>
<p>Output:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">[<span style="color:#e6db74"></span><span style="color:#e6db74">&#39;and&#39;</span>, <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;document&#39;</span>, <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;first&#39;</span>, <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;is&#39;</span>, <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;one&#39;</span>, <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;second&#39;</span>, <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;the&#39;</span>, <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;third&#39;</span>, <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;this&#39;</span>]</code></pre></div>
<p>We can use TfidfTransformer to convert count into tfidf:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> TfidfTransformer
transformer <span style="color:#f92672">=</span> TfidfTransformer(smooth_idf<span style="color:#f92672">=</span>False)
tfidf <span style="color:#f92672">=</span> transformer<span style="color:#f92672">.</span>fit_transform(X<span style="color:#f92672">.</span>toarray())
tfidf                         
tfidf<span style="color:#f92672">.</span>toarray()</code></pre></div>
<p>Output:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">array([[ <span style="color:#ae81ff">0.</span>        ,  <span style="color:#ae81ff">0.43306685</span>,  <span style="color:#ae81ff">0.56943086</span>,  <span style="color:#ae81ff">0.43306685</span>,  <span style="color:#ae81ff">0.</span>        ,
         <span style="color:#ae81ff">0.</span>        ,  <span style="color:#ae81ff">0.33631504</span>,  <span style="color:#ae81ff">0.</span>        ,  <span style="color:#ae81ff">0.43306685</span>],
       [ <span style="color:#ae81ff">0.</span>        ,  <span style="color:#ae81ff">0.24014568</span>,  <span style="color:#ae81ff">0.</span>        ,  <span style="color:#ae81ff">0.24014568</span>,  <span style="color:#ae81ff">0.</span>        ,
         <span style="color:#ae81ff">0.89006176</span>,  <span style="color:#ae81ff">0.18649454</span>,  <span style="color:#ae81ff">0.</span>        ,  <span style="color:#ae81ff">0.24014568</span>],
       [ <span style="color:#ae81ff">0.56115953</span>,  <span style="color:#ae81ff">0.</span>        ,  <span style="color:#ae81ff">0.</span>        ,  <span style="color:#ae81ff">0.</span>        ,  <span style="color:#ae81ff">0.56115953</span>,
         <span style="color:#ae81ff">0.</span>        ,  <span style="color:#ae81ff">0.23515939</span>,  <span style="color:#ae81ff">0.56115953</span>,  <span style="color:#ae81ff">0.</span>        ],
       [ <span style="color:#ae81ff">0.</span>        ,  <span style="color:#ae81ff">0.43306685</span>,  <span style="color:#ae81ff">0.56943086</span>,  <span style="color:#ae81ff">0.43306685</span>,  <span style="color:#ae81ff">0.</span>        ,
         <span style="color:#ae81ff">0.</span>        ,  <span style="color:#ae81ff">0.33631504</span>,  <span style="color:#ae81ff">0.</span>        ,  <span style="color:#ae81ff">0.43306685</span>]])</code></pre></div>
<p>Example modified from sklearn <a href="http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html">doc</a>.</p>

<h2 id="limitations-of-simple-bow">Limitations of simple BoW</h2>

<ol>
<li>The order of the words are ignored, let&rsquo;s say we know &ldquo;not&rdquo;, &ldquo;bad&rdquo;, &ldquo;good&rdquo;, &ldquo;very&rdquo; are in the same sentence, given we only know their occurance, we won&rsquo;t be able to know whether they mean &ldquo;very good&rdquo; or &ldquo;very bad&rdquo;, &ldquo;not good&rdquo; or &ldquo;not bad&rdquo; etc. There is some useful information loss, it can be partly solved by using <a href="https://en.wikipedia.org/wiki/N-gram">N-gram</a>.</li>
<li>The meaning or context of words are not able to captured in the model, similar with the example above, &ldquo;not bad&rdquo; is close to &ldquo;good&rdquo;, but in our model, they are 3 separate columns, and it is very hard to assoicate them unless we have a huge dataset with longer sentences.</li>
<li>The numbers of features generated will be huge, since we will get 1 column for each unique word in the document, also if we have a small corpus or they are all unique, it provides very little useful information for the machine learning model in the next step. This issue of sparity may cause problems in some ML models.</li>
</ol>

</div>
            <div class="footer">
                <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>

<script type="text/javascript">
    hljs.initHighlightingOnLoad();
</script>



            </div>
        </div>
        
        
<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-120240510-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='//www.google-analytics.com/analytics.js'></script>
        
    </body>
</html>
