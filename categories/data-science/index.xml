<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Science on DL</title>
    <link>https://darwinleung.github.io/categories/data-science/</link>
    <description>Recent content in Data Science on DL</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 12 May 2018 12:00:00 -0400</lastBuildDate>
    
	<atom:link href="https://darwinleung.github.io/categories/data-science/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>How does imputation work</title>
      <link>https://darwinleung.github.io/posts/2018-05-12-imputation-sklearn/</link>
      <pubDate>Sat, 12 May 2018 12:00:00 -0400</pubDate>
      
      <guid>https://darwinleung.github.io/posts/2018-05-12-imputation-sklearn/</guid>
      <description>How does imputation work? Imputation is a pre-processing technique to handle missing data before fitting the data into model. One of the simplest implementation is to estimate the missing values using the mean/median or the most frequent value of the row/ column where the missing values are located. There are more advanced ways to impute data like regressions, multiple imputation etc.
Imputer in sklearn The Imputer function in the sklearn library is commonly used in various tutorials.</description>
    </item>
    
    <item>
      <title>Extracting features from text - BoW, tfidf</title>
      <link>https://darwinleung.github.io/posts/2018-05-09-extracting-features-from-text-bow-tfidf/</link>
      <pubDate>Wed, 09 May 2018 12:00:00 -0400</pubDate>
      
      <guid>https://darwinleung.github.io/posts/2018-05-09-extracting-features-from-text-bow-tfidf/</guid>
      <description>Extracting features from text Bag-of-words TF-IDF  Term-frequency-inverse document frequency Numeriacal statistics to reflect how important a word is to a document Used as weighting factor in text mining, it can also be used to generate word vector/ matrix representation Increase proportionally to the number of times a word appears in the document offset by the frequency of the word in the corpus  $$ tfidf(t,d,D) = tf(t,d) * idf(t,D) $$</description>
    </item>
    
    <item>
      <title>Running python 2 and 3 using conda</title>
      <link>https://darwinleung.github.io/posts/2018-03-30-running-python-2-and-3-using-conda/</link>
      <pubDate>Fri, 30 Mar 2018 12:37:00 -0400</pubDate>
      
      <guid>https://darwinleung.github.io/posts/2018-03-30-running-python-2-and-3-using-conda/</guid>
      <description>I am taking the M101P course to brush up my Mongo skill, the course is kind of dated, it uses Python 2. However, I use Python 3 on my machine by default. I need a quick and easy way to run python 2 scripts without changing my default settings/path. I found conda offer a great out-of-box solution by using environment.
 A conda environment is a directory that contains a specific collection of conda packages that you have installed.</description>
    </item>
    
  </channel>
</rss>